{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the necessary packages to develop a convolutional neural network and the relevant MNIST dataset\n",
    "# if packages not yet downloaded use: pip install\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.ImageOps\n",
    "from keras.datasets import mnist\n",
    "from PIL import Image, ImageFilter\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from PIL import Image, ImageFilter, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and test dataset  \n",
    "# reshape the datasets (single channel, scale the pixels, color, float numbers) \n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "trainY = to_categorical(trainY)\n",
    "testY = to_categorical(testY)\n",
    "train_norm = trainX.astype('float32')\n",
    "test_norm = testX.astype('float32')\n",
    "\n",
    "# normalize the data to a range of 0-1 by dividing throug maximum value\n",
    "# blablabla new comment\n",
    "train_norm = train_norm / 255.0\n",
    "test_norm = test_norm / 255.0\n",
    "trainX = train_norm\n",
    "testX = test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               540900    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 542,230\n",
      "Trainable params: 542,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a sequential model (stack of layers where each layer has exactly one input tensor and one output tensor)\n",
    "# layer Conv2D: creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs\n",
    "# layer MaxPooling2D: downsamples the input for 2D spatial data\n",
    "# layer Flatten: flattens input without affecting batch size\n",
    "# layer Dense 1: regular densely-connected neural network layer, relu applies the rectified linear unit activation function\n",
    "# layer Dense 2: regular densely-connected neural network layer, softmax converts a real vector to a vector of categorical probabilities, sum of vector element =1 \n",
    "new_model = Sequential()\n",
    "new_model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "new_model.add(MaxPooling2D((2, 2)))\n",
    "new_model.add(Flatten())\n",
    "new_model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "new_model.add(Dense(10, activation='softmax'))\n",
    "new_model.summary()\n",
    "    \n",
    "# optimize(with learning rate and momentum) and compile the model \n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "new_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1648 - accuracy: 0.9496\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0561 - accuracy: 0.9830\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0354 - accuracy: 0.9889\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0251 - accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0171 - accuracy: 0.9948\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0120 - accuracy: 0.9965\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0030 - accuracy: 0.9996\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0020 - accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b9a8eb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model based on the training data set\n",
    "# epochs = cutoff to separate training data in distinct phases (means we are going 10 times throug training dataset)\n",
    "# batch_size = number of samples per gradient update\n",
    "new_model.fit(trainX, trainY, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0412 - accuracy: 0.9875\n",
      "\n",
      "Test accuracy: 0.987500011920929\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained model based on the test accuray for the test dataset\n",
    "test_loss, test_acc =new_model.evaluate(testX, testY, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# test accuracy of 98.8 percent evaluated as reasonably accurate - we proceed\n",
    "# done with the model construction and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "(296, 322)\n",
      "(20, 20)\n",
      "<class 'PIL.Image.Image'>\n",
      "<PIL.Image.Image image mode=L size=20x20 at 0x138EA6B20>\n",
      "111\n",
      "<class 'numpy.ndarray'>\n",
      "[[253. 255. 196. 120. 119. 126. 143. 152. 160. 167. 179. 186. 187. 187.\n",
      "  191. 198. 208. 233. 255. 255.]\n",
      " [255. 255.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0. 115. 254.]\n",
      " [254. 255.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0. 244.]\n",
      " [254. 255. 255. 238. 246. 233. 204. 193. 185. 167. 147. 137. 135. 158.\n",
      "  143.   0.   1.   0.  72. 254.]\n",
      " [255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      "  117.   0.   0.  13. 255. 253.]\n",
      " [255. 255. 253. 250. 250. 250. 248. 248. 248. 249. 249. 243. 255. 235.\n",
      "    0.   0.   0. 255. 255. 253.]\n",
      " [255. 255. 255. 255. 255. 255. 255. 255. 255. 253. 254. 255. 255.  11.\n",
      "    0.   0. 102. 255. 252. 255.]\n",
      " [255. 255. 255. 255. 255. 255. 255. 253. 255. 255. 255. 255. 209.   0.\n",
      "    0.   1. 255. 255. 255. 255.]\n",
      " [255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.   0.   0.\n",
      "    0.  60. 140. 249. 255. 253.]\n",
      " [255. 255. 255. 255. 255. 254. 255. 255.   0.   0.   0.   0.   0.   0.\n",
      "    1.   0.   0.   0. 255. 253.]\n",
      " [255. 255. 255. 255. 255. 249. 255. 210.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.  62. 255. 253.]\n",
      " [255. 255. 255. 255. 255. 255. 255. 255.  98. 103.   8.   0.   0.   7.\n",
      "  153. 211. 255. 255. 255. 255.]\n",
      " [255. 255. 255. 255. 255. 255. 255. 255. 255. 255.   0.   0.   0. 255.\n",
      "  255. 255. 255. 255. 255. 255.]\n",
      " [255. 255. 255. 255. 255. 255. 254. 255. 255.   0.   0.   0. 116. 255.\n",
      "  248. 250. 251. 255. 255. 255.]\n",
      " [255. 255. 255. 255. 255. 255. 255. 255. 114.   0.   0.   0. 255. 255.\n",
      "  255. 255. 255. 255. 255. 255.]\n",
      " [255. 255. 255. 255. 255. 252. 255. 255.   0.   0.   0. 240. 255. 251.\n",
      "  255. 255. 255. 255. 255. 255.]\n",
      " [255. 255. 255. 255. 255. 248. 255.  38.   0.   0.  56. 255. 255. 255.\n",
      "  255. 255. 255. 255. 255. 255.]\n",
      " [255. 255. 255. 255. 255. 250. 255.  95.   0.   0. 255. 255. 252. 255.\n",
      "  255. 255. 255. 255. 255. 255.]\n",
      " [255. 255. 255. 255. 255. 255. 255. 255. 219. 255. 255. 255. 255. 255.\n",
      "  255. 255. 255. 255. 255. 255.]\n",
      " [255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 254. 255. 255. 255.\n",
      "  255. 255. 255. 255. 255. 255.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build an image converter with the aim that the model predicts the digit of the new uploaded image \n",
    "# open the image, if saved in the same dictionary the name suffices, otherwise use whole savepath\n",
    "im = Image.open('IMG7.png')\n",
    "\n",
    "# get the bands in the image since python imaging library allows to store several band in a single image\n",
    "im.getbands() \n",
    "\n",
    "# define type and depth of a pixel in the image\n",
    "# use mode L: 8-bit pixels (has a range of 0-255), black and white\n",
    "im = im.convert('L') \n",
    "im.getbands()\n",
    "print(type(im)) \n",
    "print(im.size) \n",
    "\n",
    "# resizing and quality enhancement of the image\n",
    "im = im.resize((20,20), Image.LANCZOS) \n",
    "im = im.filter(ImageFilter.SHARPEN) \n",
    "print(im.size) \n",
    "print(type(im)) \n",
    "print(im) \n",
    "\n",
    "# convert to a numpy array\n",
    "test = np.array(im, dtype='float32')\n",
    "print(type(test))\n",
    "print(test)\n",
    "\n",
    "# examination of the image format through visualization\n",
    "# plot will appear at the end of the output\n",
    "plt.imshow(test, cmap='gray') \n",
    "\n",
    "# insight: Color of the image has to be inverted because in the MNIST dataset they are written in with on a black canvas\n",
    "# insight: Digit needs to be centered\n",
    "\n",
    "# implementation of color inversion (now black = 0 and white = 255, mode L)\n",
    "newImage = Image.new('L', (28, 28), (255)) \n",
    "\n",
    "# implementation of image centralization (vertical and horizontal distance from upper left corner)\n",
    "newImage.paste(im,(4,4)) \n",
    "\n",
    "# invert the colors of the image (change black and white) \n",
    "# visualization: illustration of the shape to be recognized by the model (opened in a new window)\n",
    "inverted_image = PIL.ImageOps.invert(newImage)\n",
    "inverted_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   2.   0.  59. 135. 136. 129. 112. 103.  95.  88.\n",
      "   76.  69.  68.  68.  64.  57.  47.  22.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      "  255. 255. 255. 255. 255. 255. 255. 255. 140.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   1.   0. 255. 255. 255. 255. 255. 255. 255. 255.\n",
      "  255. 255. 255. 255. 255. 255. 255. 255. 255.  11.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   1.   0.   0.  17.   9.  22.  51.  62.  70.  88.\n",
      "  108. 118. 120.  97. 112. 255. 254. 255. 183.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0. 138. 255. 255. 242.   0.   2.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   2.   5.   5.   5.   7.   7.   7.   6.\n",
      "    6.  12.   0.  20. 255. 255. 255.   0.   0.   2.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   2.\n",
      "    1.   0.   0. 244. 255. 255. 153.   0.   3.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   2.   0.   0.\n",
      "    0.   0.  46. 255. 255. 254.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0. 255. 255. 255. 195. 115.   6.   0.   2.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0. 255. 255.\n",
      "  255. 255. 255. 255. 254. 255. 255. 255.   0.   2.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   6.   0.  45. 255. 255.\n",
      "  255. 255. 255. 255. 255. 255. 255. 193.   0.   2.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 157. 152.\n",
      "  247. 255. 255. 248. 102.  44.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  255. 255. 255.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0. 255.\n",
      "  255. 255. 139.   0.   7.   5.   4.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 141. 255.\n",
      "  255. 255.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   3.   0.   0. 255. 255.\n",
      "  255.  15.   0.   4.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   7.   0. 217. 255. 255.\n",
      "  199.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   5.   0. 160. 255. 255.\n",
      "    0.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  36.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00784314 0.\n",
      "  0.23137255 0.5294118  0.53333336 0.5058824  0.4392157  0.40392157\n",
      "  0.37254903 0.34509805 0.29803923 0.27058825 0.26666668 0.26666668\n",
      "  0.2509804  0.22352941 0.18431373 0.08627451 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         0.54901963 0.00392157\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00392157 0.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         0.04313726\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00392157 0.\n",
      "  0.         0.06666667 0.03529412 0.08627451 0.2        0.24313726\n",
      "  0.27450982 0.34509805 0.42352942 0.4627451  0.47058824 0.38039216\n",
      "  0.4392157  1.         0.99607843 1.         0.7176471  0.00392157\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.5411765  1.         1.         0.9490196  0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.00784314 0.01960784 0.01960784 0.01960784 0.02745098 0.02745098\n",
      "  0.02745098 0.02352941 0.02352941 0.04705882 0.         0.07843138\n",
      "  1.         1.         1.         0.         0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00784314 0.00392157 0.         0.         0.95686275\n",
      "  1.         1.         0.6        0.         0.01176471 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00784314\n",
      "  0.         0.         0.         0.         0.18039216 1.\n",
      "  1.         0.99607843 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.         1.\n",
      "  1.         0.7647059  0.4509804  0.02352941 0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.         0.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  0.99607843 1.         1.         1.         0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02352941 0.         0.1764706\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         0.75686276 0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.6156863  0.59607846 0.96862745 1.         1.         0.972549\n",
      "  0.4        0.17254902 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         1.         1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00392157 0.\n",
      "  0.         1.         1.         1.         0.54509807 0.\n",
      "  0.02745098 0.01960784 0.01568628 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.5529412  1.         1.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01176471 0.         0.\n",
      "  1.         1.         1.         0.05882353 0.         0.01568628\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02745098 0.         0.8509804\n",
      "  1.         1.         0.78039217 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01960784 0.         0.627451\n",
      "  1.         1.         0.         0.         0.01176471 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14117648 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert the image to a numpy array\n",
    "# scale the image down to values between 0 - 1 by dividing through maximum (255)\n",
    "inverted_image = np.array(inverted_image, dtype='float32')\n",
    "print(type(inverted_image))\n",
    "print(inverted_image)\n",
    "inverted_image = inverted_image / 255.0 \n",
    "print(inverted_image)\n",
    "print(type(inverted_image))\n",
    "\n",
    "# reshape the image in order to meet the form requirements for the neural network\n",
    "inverted_image = inverted_image.reshape((1,28,28,1))\n",
    "print(type(inverted_image))\n",
    "print(inverted_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.0283244e-11 2.9831498e-11 4.7577661e-04 3.5792090e-02 2.8261004e-13\n",
      "  1.5884014e-16 5.9885853e-13 9.6373081e-01 1.1577955e-06 2.0970896e-07]]\n",
      "The hand written digit was classified as the digit : 7\n"
     ]
    }
   ],
   "source": [
    "# predict the digit of our own image with the trained and tested model\n",
    "# output with highest probability corresponds to the predicted digit by the model\n",
    "predictions = new_model.predict(inverted_image)\n",
    "print(predictions)\n",
    "print(\"The hand written digit was classified as the digit :\",np.argmax(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization of the predicted probability for each digit\n",
    "plt.bar(np.arange(len(predictions[0])),predictions[0])\n",
    "plt.xticks(np.arange(len(predictions[0])))\n",
    "plt.ylim(0, 1.1)\n",
    "plt.hlines(1,0,9,color='gray',linestyles='dotted')\n",
    "plt.title(\"Prediction probability\")\n",
    "plt.xlabel(\"Predicted digit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
